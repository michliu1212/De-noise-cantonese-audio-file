{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "miniature-price",
   "metadata": {},
   "source": [
    "The Microsoft Scalable Noisy Speech Dataset (MS-SNSD) is a noisy speech dataset that can scale to arbitrary sizes depending on the number of speakers, noise types, and Speech to Noise Ratio (SNR) levels desired.\n",
    "\n",
    "a noisy speech dataset (MS-SNSD) that can scale to arbitrary sizes depending on the number of speakers, noise types, and Speech to Noise Ratio (SNR) levels desired\n",
    "\n",
    "n data augmentation \n",
    "Source: https://github.com/microsoft/MS-SNSD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "solved-casting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "given-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "os. chdir('/Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2/clean_train') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "postal-spectrum",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_dir /Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2/clean_train/clean_train\n"
     ]
    }
   ],
   "source": [
    "clean_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'clean_train')\n",
    "print('clean_dir', clean_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "qualified-constraint",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='Cantonese1.wav'>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert file to wav. format\n",
    "\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "# files                                                                         \n",
    "src = \"Cantonese1.mov\"\n",
    "dst = \"Cantonese1.wav\"\n",
    "#cleanfilenames = glob.glob(os.path.join(src, \".mov\"))\n",
    "# convert mov to wav                                                            \n",
    "sound = AudioSegment.from_file(src, format=\"mov\")\n",
    "sound = sound.set_channels(1)\n",
    "sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "strategic-duplicate",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<_io.BufferedRandom name='Cantonese5.wav'>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "src = \"Cantonese2.mov\"\n",
    "dst = \"Cantonese2.wav\"\n",
    "#cleanfilenames = glob.glob(os.path.join(src, \".mov\"))\n",
    "# convert mov to wav                                                            \n",
    "sound = AudioSegment.from_file(src, format=\"mov\")\n",
    "sound = sound.set_channels(1)\n",
    "sound.export(dst, format=\"wav\")\n",
    "src = \"Cantonese3.mov\"\n",
    "dst = \"Cantonese3.wav\"\n",
    "#cleanfilenames = glob.glob(os.path.join(src, \".mov\"))\n",
    "# convert mov to wav                                                            \n",
    "sound = AudioSegment.from_file(src, format=\"mov\")\n",
    "sound = sound.set_channels(1)\n",
    "sound.export(dst, format=\"wav\")\n",
    "src = \"Cantonese4.mov\"\n",
    "dst = \"Cantonese4.wav\"\n",
    "#cleanfilenames = glob.glob(os.path.join(src, \".mov\"))\n",
    "# convert mov to wav                                                            \n",
    "sound = AudioSegment.from_file(src, format=\"mov\")\n",
    "sound = sound.set_channels(1)\n",
    "sound.export(dst, format=\"wav\")\n",
    "src = \"Cantonese5.mov\"\n",
    "dst = \"Cantonese5.wav\"\n",
    "#cleanfilenames = glob.glob(os.path.join(src, \".mov\"))\n",
    "# convert mov to wav                                                            \n",
    "sound = AudioSegment.from_file(src, format=\"mov\")\n",
    "sound = sound.set_channels(1)\n",
    "sound.export(dst, format=\"wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "utility-serve",
   "metadata": {},
   "outputs": [],
   "source": [
    "os. chdir('/Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "positive-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import sounddevice as sd\n",
    "\n",
    "# Function to read audio\n",
    "def audioread(path, norm = True, start=0, stop=None):\n",
    "    path = os.path.abspath(path)\n",
    "    if not os.path.exists(path):\n",
    "        raise ValueError(\"[{}] does not exist!\".format(path))\n",
    "    try:\n",
    "        x, sr = sf.read(path, start=start, stop=stop)\n",
    "    except RuntimeError:  # fix for sph pcm-embedded shortened v2\n",
    "        print('WARNING: Audio type not supported')\n",
    "\n",
    "    if len(x.shape) == 1:  # mono\n",
    "        if norm:\n",
    "            rms = (x ** 2).mean() ** 0.5\n",
    "            scalar = 10 ** (-25 / 20) / (rms)\n",
    "            x = x * scalar\n",
    "        return x, sr\n",
    "    else:  # multi-channel\n",
    "        x = x.T\n",
    "        x = x.sum(axis=0)/x.shape[0]\n",
    "        if norm:\n",
    "            rms = (x ** 2).mean() ** 0.5\n",
    "            scalar = 10 ** (-25 / 20) / (rms)\n",
    "            x = x * scalar\n",
    "        return x, sr\n",
    "    \n",
    "# Funtion to write audio    \n",
    "def audiowrite(data, fs, destpath, norm=False):\n",
    "    if norm:\n",
    "        rms = (data ** 2).mean() ** 0.5\n",
    "        scalar = 10 ** (-25 / 10) / (rms+eps)\n",
    "        data = data * scalar\n",
    "        if max(abs(data))>=1:\n",
    "            data = data/max(abs(data), eps)\n",
    "    \n",
    "    destpath = os.path.abspath(destpath)\n",
    "    destdir = os.path.dirname(destpath)\n",
    "    \n",
    "    if not os.path.exists(destdir):\n",
    "        os.makedirs(destdir)\n",
    "    \n",
    "    sf.write(destpath, data, fs)\n",
    "    return\n",
    "\n",
    "# Function to mix clean speech and noise at various signal to noise ratio (SNR) levels\n",
    "def snr_mixer(clean, noise, snr):\n",
    "    # Normalizing to -25 dB FS\n",
    "    rmsclean = (clean**2).mean()**0.5\n",
    "    scalarclean = 10 ** (-25 / 20) / rmsclean\n",
    "    clean = clean * scalarclean\n",
    "    rmsclean = (clean**2).mean()**0.5\n",
    "\n",
    "    rmsnoise = (noise**2).mean()**0.5\n",
    "    scalarnoise = 10 ** (-25 / 20) /rmsnoise\n",
    "    noise = noise * scalarnoise\n",
    "    rmsnoise = (noise**2).mean()**0.5\n",
    "    \n",
    "    # Set the noise level for a given SNR\n",
    "    noisescalar = np.sqrt(rmsclean / (10**(snr/20)) / rmsnoise)\n",
    "    noisenewlevel = noise * noisescalar\n",
    "    noisyspeech = clean + noisenewlevel\n",
    "    return clean, noisenewlevel, noisyspeech\n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "intended-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for generating Noisy Speech Dataset\n",
    "\n",
    "# - sampling_rate: Specify the sampling rate. Default is 16 kHz\n",
    "# - audioformat: default is .wav\n",
    "# - audio_length: Max Length of each audio clip (noisy and clean speech) in seconds that will be generated by augmenting utterances. \n",
    "# - silence_length: Duration of silence introduced between clean speech utterances.\n",
    "# - total_hours: Total number of hours of data required. Units are in hours. \n",
    "# - snr_lower: Lower bound for SNR required (default: 0 dB)\n",
    "# - snr_upper: Upper bound for SNR required (default: 40 dB)\n",
    "# - total_snrlevels: Number of SNR levels required (default: 5, which means there are 5 levels between snr_lower and snr_upper)\n",
    "# - noise_dir: Default is None. But specify the noise directory path if noise files are not in the source directory\n",
    "# - Speech_dir: Default is None. But specify the speech directory path if speech files are not in the source directory\n",
    "# - noise_types_excluded: Noise files starting with the following tags to be excluded in the noise list. Example: noise_types_excluded: Babble, AirConditioner\n",
    "#                         Specify 'None' if no noise files to be excluded.\n",
    "\n",
    "cfg={\n",
    "'sampling_rate': 44100,\n",
    "'audioformat': '*.wav',\n",
    "'audio_length': 60,\n",
    "'silence_length': 0.2,\n",
    "'total_hours': 1 ,\n",
    "'snr_lower': 0,\n",
    "'snr_upper': 40,\n",
    "'total_snrlevels': 5,  \n",
    "\n",
    "'noise_dir': None,\n",
    "'speech_dir': None,\n",
    "'noise_types_excluded': 'SqueakyChair',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "national-opinion",
   "metadata": {},
   "outputs": [],
   "source": [
    "snr_lower = int(cfg['snr_lower'])\n",
    "snr_upper = int(cfg['snr_upper'])\n",
    "total_snrlevels = int(cfg['total_snrlevels'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "polish-warning",
   "metadata": {},
   "source": [
    "## create noisy training file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "unknown-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_dir /Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2/clean_train\n",
      "noise_dir /Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2/noise_train\n"
     ]
    }
   ],
   "source": [
    "clean_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'clean_train')\n",
    "print('clean_dir', clean_dir)\n",
    "noise_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'noise_train')\n",
    "print('noise_dir', noise_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "associate-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = float(cfg[\"sampling_rate\"])\n",
    "audioformat = cfg[\"audioformat\"]\n",
    "total_hours = float(cfg[\"total_hours\"])\n",
    "audio_length = float(cfg[\"audio_length\"])\n",
    "silence_length = float(cfg[\"silence_length\"])\n",
    "noisyspeech_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'NoisySpeech_training')\n",
    "if not os.path.exists(noisyspeech_dir):\n",
    "    os.makedirs(noisyspeech_dir)\n",
    "clean_proc_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'CleanSpeech_training')\n",
    "if not os.path.exists(clean_proc_dir):\n",
    "    os.makedirs(clean_proc_dir)\n",
    "noise_proc_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'Noise_training')\n",
    "if not os.path.exists(noise_proc_dir):\n",
    "    os.makedirs(noise_proc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "worldwide-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_secs = total_hours*60*60\n",
    "total_samples = int(total_secs * fs)\n",
    "audio_length = int(audio_length*fs)\n",
    "SNR = np.linspace(snr_lower, snr_upper, total_snrlevels)\n",
    "cleanfilenames = glob.glob(os.path.join(clean_dir, audioformat))\n",
    "if cfg[\"noise_types_excluded\"]==None:\n",
    "    noisefilenames = glob.glob(os.path.join(noise_dir, audioformat))\n",
    "else:\n",
    "    filestoexclude = cfg[\"noise_types_excluded\"].split(',')\n",
    "    noisefilenames = glob.glob(os.path.join(noise_dir, audioformat))\n",
    "    for i in range(len(filestoexclude)):\n",
    "        noisefilenames = [fn for fn in noisefilenames if not os.path.basename(fn).startswith(filestoexclude[i])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "honest-blank",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Typing_8\n",
      "noisy_Cantonese3_SNRdb_0_Typing_8.wav\n",
      "Typing_8\n",
      "noisy_Cantonese3_SNRdb_10_Typing_8.wav\n",
      "Typing_8\n",
      "noisy_Cantonese3_SNRdb_20_Typing_8.wav\n",
      "Typing_8\n",
      "noisy_Cantonese3_SNRdb_30_Typing_8.wav\n",
      "Typing_8\n",
      "noisy_Cantonese3_SNRdb_40_Typing_8.wav\n",
      "AirportAnnouncements_5\n",
      "noisy_Cantonese2_SNRdb_0_AirportAnnouncements_5.wav\n",
      "AirportAnnouncements_5\n",
      "noisy_Cantonese2_SNRdb_10_AirportAnnouncements_5.wav\n",
      "AirportAnnouncements_5\n",
      "noisy_Cantonese2_SNRdb_20_AirportAnnouncements_5.wav\n",
      "AirportAnnouncements_5\n",
      "noisy_Cantonese2_SNRdb_30_AirportAnnouncements_5.wav\n",
      "AirportAnnouncements_5\n",
      "noisy_Cantonese2_SNRdb_40_AirportAnnouncements_5.wav\n",
      "CopyMachine_10\n",
      "noisy_Cantonese3_SNRdb_0_CopyMachine_10.wav\n",
      "CopyMachine_10\n",
      "noisy_Cantonese3_SNRdb_10_CopyMachine_10.wav\n",
      "CopyMachine_10\n",
      "noisy_Cantonese3_SNRdb_20_CopyMachine_10.wav\n",
      "CopyMachine_10\n",
      "noisy_Cantonese3_SNRdb_30_CopyMachine_10.wav\n",
      "CopyMachine_10\n",
      "noisy_Cantonese3_SNRdb_40_CopyMachine_10.wav\n",
      "Munching_9\n",
      "noisy_Cantonese5_SNRdb_0_Munching_9.wav\n",
      "Munching_9\n",
      "noisy_Cantonese5_SNRdb_10_Munching_9.wav\n",
      "Munching_9\n",
      "noisy_Cantonese5_SNRdb_20_Munching_9.wav\n",
      "Munching_9\n",
      "noisy_Cantonese5_SNRdb_30_Munching_9.wav\n",
      "Munching_9\n",
      "noisy_Cantonese5_SNRdb_40_Munching_9.wav\n",
      "AirConditioner_4\n",
      "noisy_Cantonese3_SNRdb_0_AirConditioner_4.wav\n",
      "AirConditioner_4\n",
      "noisy_Cantonese3_SNRdb_10_AirConditioner_4.wav\n",
      "AirConditioner_4\n",
      "noisy_Cantonese3_SNRdb_20_AirConditioner_4.wav\n",
      "AirConditioner_4\n",
      "noisy_Cantonese3_SNRdb_30_AirConditioner_4.wav\n",
      "AirConditioner_4\n",
      "noisy_Cantonese3_SNRdb_40_AirConditioner_4.wav\n",
      "VacuumCleaner_8\n",
      "noisy_Cantonese3_SNRdb_0_VacuumCleaner_8.wav\n",
      "VacuumCleaner_8\n",
      "noisy_Cantonese3_SNRdb_10_VacuumCleaner_8.wav\n",
      "VacuumCleaner_8\n",
      "noisy_Cantonese3_SNRdb_20_VacuumCleaner_8.wav\n",
      "VacuumCleaner_8\n",
      "noisy_Cantonese3_SNRdb_30_VacuumCleaner_8.wav\n",
      "VacuumCleaner_8\n",
      "noisy_Cantonese3_SNRdb_40_VacuumCleaner_8.wav\n",
      "Typing_5\n",
      "noisy_Cantonese4_SNRdb_0_Typing_5.wav\n",
      "Typing_5\n",
      "noisy_Cantonese4_SNRdb_10_Typing_5.wav\n",
      "Typing_5\n",
      "noisy_Cantonese4_SNRdb_20_Typing_5.wav\n",
      "Typing_5\n",
      "noisy_Cantonese4_SNRdb_30_Typing_5.wav\n",
      "Typing_5\n",
      "noisy_Cantonese4_SNRdb_40_Typing_5.wav\n",
      "AirConditioner_2\n",
      "noisy_Cantonese5_SNRdb_0_AirConditioner_2.wav\n",
      "AirConditioner_2\n",
      "noisy_Cantonese5_SNRdb_10_AirConditioner_2.wav\n",
      "AirConditioner_2\n",
      "noisy_Cantonese5_SNRdb_20_AirConditioner_2.wav\n",
      "AirConditioner_2\n",
      "noisy_Cantonese5_SNRdb_30_AirConditioner_2.wav\n",
      "AirConditioner_2\n",
      "noisy_Cantonese5_SNRdb_40_AirConditioner_2.wav\n",
      "Typing_2\n",
      "noisy_Cantonese2_SNRdb_0_Typing_2.wav\n",
      "Typing_2\n",
      "noisy_Cantonese2_SNRdb_10_Typing_2.wav\n",
      "Typing_2\n",
      "noisy_Cantonese2_SNRdb_20_Typing_2.wav\n",
      "Typing_2\n",
      "noisy_Cantonese2_SNRdb_30_Typing_2.wav\n",
      "Typing_2\n",
      "noisy_Cantonese2_SNRdb_40_Typing_2.wav\n",
      "AirConditioner_6\n",
      "noisy_Cantonese3_SNRdb_0_AirConditioner_6.wav\n",
      "AirConditioner_6\n",
      "noisy_Cantonese3_SNRdb_10_AirConditioner_6.wav\n",
      "AirConditioner_6\n",
      "noisy_Cantonese3_SNRdb_20_AirConditioner_6.wav\n",
      "AirConditioner_6\n",
      "noisy_Cantonese3_SNRdb_30_AirConditioner_6.wav\n",
      "AirConditioner_6\n",
      "noisy_Cantonese3_SNRdb_40_AirConditioner_6.wav\n",
      "AirportAnnouncements_3\n",
      "noisy_Cantonese3_SNRdb_0_AirportAnnouncements_3.wav\n",
      "AirportAnnouncements_3\n",
      "noisy_Cantonese3_SNRdb_10_AirportAnnouncements_3.wav\n",
      "AirportAnnouncements_3\n",
      "noisy_Cantonese3_SNRdb_20_AirportAnnouncements_3.wav\n",
      "AirportAnnouncements_3\n",
      "noisy_Cantonese3_SNRdb_30_AirportAnnouncements_3.wav\n",
      "AirportAnnouncements_3\n",
      "noisy_Cantonese3_SNRdb_40_AirportAnnouncements_3.wav\n",
      "Munching_6\n",
      "noisy_Cantonese2_SNRdb_0_Munching_6.wav\n",
      "Munching_6\n",
      "noisy_Cantonese2_SNRdb_10_Munching_6.wav\n",
      "Munching_6\n",
      "noisy_Cantonese2_SNRdb_20_Munching_6.wav\n",
      "Munching_6\n",
      "noisy_Cantonese2_SNRdb_30_Munching_6.wav\n",
      "Munching_6\n",
      "noisy_Cantonese2_SNRdb_40_Munching_6.wav\n",
      "NeighborSpeaking_12\n",
      "noisy_Cantonese1_SNRdb_0_NeighborSpeaking_12.wav\n",
      "NeighborSpeaking_12\n",
      "noisy_Cantonese1_SNRdb_10_NeighborSpeaking_12.wav\n",
      "NeighborSpeaking_12\n",
      "noisy_Cantonese1_SNRdb_20_NeighborSpeaking_12.wav\n",
      "NeighborSpeaking_12\n",
      "noisy_Cantonese1_SNRdb_30_NeighborSpeaking_12.wav\n",
      "NeighborSpeaking_12\n",
      "noisy_Cantonese1_SNRdb_40_NeighborSpeaking_12.wav\n",
      "AirportAnnouncements_3\n",
      "noisy_Cantonese5_SNRdb_0_AirportAnnouncements_3.wav\n",
      "AirportAnnouncements_3\n",
      "noisy_Cantonese5_SNRdb_10_AirportAnnouncements_3.wav\n",
      "AirportAnnouncements_3\n",
      "noisy_Cantonese5_SNRdb_20_AirportAnnouncements_3.wav\n",
      "AirportAnnouncements_3\n",
      "noisy_Cantonese5_SNRdb_30_AirportAnnouncements_3.wav\n",
      "AirportAnnouncements_3\n",
      "noisy_Cantonese5_SNRdb_40_AirportAnnouncements_3.wav\n",
      "WasherDryer_1\n",
      "noisy_Cantonese4_SNRdb_0_WasherDryer_1.wav\n",
      "WasherDryer_1\n",
      "noisy_Cantonese4_SNRdb_10_WasherDryer_1.wav\n",
      "WasherDryer_1\n",
      "noisy_Cantonese4_SNRdb_20_WasherDryer_1.wav\n",
      "WasherDryer_1\n",
      "noisy_Cantonese4_SNRdb_30_WasherDryer_1.wav\n",
      "WasherDryer_1\n",
      "noisy_Cantonese4_SNRdb_40_WasherDryer_1.wav\n",
      "Field_1\n",
      "noisy_Cantonese4_SNRdb_0_Field_1.wav\n",
      "Field_1\n",
      "noisy_Cantonese4_SNRdb_10_Field_1.wav\n",
      "Field_1\n",
      "noisy_Cantonese4_SNRdb_20_Field_1.wav\n",
      "Field_1\n",
      "noisy_Cantonese4_SNRdb_30_Field_1.wav\n",
      "Field_1\n",
      "noisy_Cantonese4_SNRdb_40_Field_1.wav\n",
      "AirportAnnouncements_8\n",
      "noisy_Cantonese5_SNRdb_0_AirportAnnouncements_8.wav\n",
      "AirportAnnouncements_8\n",
      "noisy_Cantonese5_SNRdb_10_AirportAnnouncements_8.wav\n",
      "AirportAnnouncements_8\n",
      "noisy_Cantonese5_SNRdb_20_AirportAnnouncements_8.wav\n",
      "AirportAnnouncements_8\n",
      "noisy_Cantonese5_SNRdb_30_AirportAnnouncements_8.wav\n",
      "AirportAnnouncements_8\n",
      "noisy_Cantonese5_SNRdb_40_AirportAnnouncements_8.wav\n"
     ]
    }
   ],
   "source": [
    "\n",
    "filecounter = 0\n",
    "num_samples = 0\n",
    "#fs2= 44100\n",
    "    \n",
    "while num_samples < total_samples:\n",
    "    idx_s = np.random.randint(0, np.size(cleanfilenames))\n",
    "    #print('cleanfilenames[idx_s]', cleanfilenames[idx_s])\n",
    "    clean, fs = audioread(cleanfilenames[idx_s])\n",
    "    \n",
    "    if len(clean)<audio_length:\n",
    "        clean = clean\n",
    "       \n",
    "        \n",
    "    else:\n",
    "            \n",
    "        while len(clean)<=audio_length:\n",
    "            idx_s = idx_s + 1\n",
    "            if idx_s >= np.size(cleanfilenames)-1:\n",
    "                idx_s = np.random.randint(0, np.size(cleanfilenames)) \n",
    "            newclean, fs = audioread(cleanfilenames[idx_s])\n",
    "            cleanconcat = np.append(clean, np.zeros(int(fs*silence_length)))\n",
    "            clean = np.append(cleanconcat, newclean)\n",
    "\n",
    "\n",
    "    idx_n = np.random.randint(0, np.size(noisefilenames))\n",
    "    noise, fs2 = audioread(noisefilenames[idx_n])\n",
    "    idx2 = idx_n\n",
    "    \n",
    "    # Resample data\n",
    "    new_rate = 44100\n",
    "    number_of_samples = round(len(noise) * float(new_rate) / fs2)\n",
    "    noise = sps.resample(noise, number_of_samples)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "        \n",
    "    if len(noise)>=len(clean):\n",
    "        noise = noise[0:len(clean)]\n",
    "        #noise_filename = noisefilenames[idx_n]\n",
    "        \n",
    "    else:\n",
    "        \n",
    "        while len(noise)<=len(clean):\n",
    "            idx_n = idx_n + 1\n",
    "            if idx_n >= np.size(noisefilenames)-1:\n",
    "                idx_n = np.random.randint(0, np.size(noisefilenames))\n",
    "            newnoise, fs2 = audioread(noisefilenames[idx_n])\n",
    "            idx2 = idx_n\n",
    "             # Resample data\n",
    "            new_rate = 44100\n",
    "            number_of_samples = round(len(noise) * float(new_rate) / fs2)\n",
    "            noise = sps.resample(noise, number_of_samples)\n",
    "            \n",
    "            noiseconcat = np.append(noise, np.zeros(int(fs*silence_length)))\n",
    "            noise = np.append(noiseconcat, newnoise)\n",
    "            #noise_filename = noisefilenames[idx_n]\n",
    "    #print((noise_filename.split(\"/\")[-1].split('.')[0]))\n",
    "    noise = noise[0:len(clean)]\n",
    "    filecounter = filecounter + 1\n",
    "\n",
    "        \n",
    "    #print('filecounter', filecounter)\n",
    "    \n",
    "    \n",
    "\n",
    "    for i in range(np.size(SNR)):\n",
    "        clean_snr, noise_snr, noisy_snr = snr_mixer(clean=clean, noise=noise, snr=SNR[i])\n",
    "        noise_filename = noisefilenames[idx2]\n",
    "        print((noise_filename.split(\"/\")[-1].split('.')[0]))\n",
    "        \n",
    "        noisyfilename = 'noisy_'+(cleanfilenames[idx_s].split(\"/\")[-1].split('.')[0])+'_SNRdb_'+str(int(SNR[i]))+ '_'+ (noise_filename.split(\"/\")[-1].split('.')[0]) +'.wav'\n",
    "        cleanfilename = 'clnsp_'+(cleanfilenames[idx_s].split(\"/\")[-1].split('.')[0])+'.wav'\n",
    "        noisefilename = 'noisy_'+(cleanfilenames[idx_s].split(\"/\")[-1].split('.')[0])+'_SNRdb_'+str(int(SNR[i]))+ '_'+ (noise_filename.split(\"/\")[-1].split('.')[0]) +'.wav'\n",
    "        noisypath = os.path.join(noisyspeech_dir, noisyfilename)\n",
    "        cleanpath = os.path.join(clean_proc_dir, cleanfilename)\n",
    "        noisepath = os.path.join(noise_proc_dir, noisefilename)\n",
    "        print(noisyfilename )\n",
    "        audiowrite(noisy_snr, fs, noisypath, norm=False)\n",
    "        audiowrite(clean, fs, cleanpath, norm=False)\n",
    "        audiowrite(noise_snr, fs, noisepath, norm=False)\n",
    "        num_samples = num_samples + len(noisy_snr)\n",
    "        \n",
    "        #sd.play(clean, fs)\n",
    "        #status = sd.wait() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "exempt-integration",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.size(noisefilenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "incorrect-parallel",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
