{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "miniature-price",
   "metadata": {},
   "source": [
    "# Data preparation\n",
    "\n",
    "Main dataset: \n",
    "Cantonese youtube videos are downloaded and converted to WAV file as the clean audio data\n",
    "\n",
    "Noise dataset: \n",
    "A folder of background noise WAV file from [Microsoft Scalable Noisy Speech Dataset (MS-SNSD)](https://github.com/microsoft/MS-SNSD) with white noise and recordings of machinery and everyday household activities are used in this analysis to add noises on the cantonese audio. The loudness of the background noise are used in 4 levels, with 10 the largest and 40 the smallest. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "human-chosen",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import os\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import os\n",
    "import numpy as np\n",
    "import glob\n",
    "import sounddevice as sd\n",
    "import scipy.signal as sps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "worst-nitrogen",
   "metadata": {},
   "source": [
    "## Convert audio files to wav. format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "solved-casting",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2'"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cwd = os.getcwd()\n",
    "cwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "given-benchmark",
   "metadata": {},
   "outputs": [],
   "source": [
    "os. chdir('/Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2/clean_train') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "spiritual-glenn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_dir /Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2/clean_train/clean_train\n"
     ]
    }
   ],
   "source": [
    "# Set clean audio directory\n",
    "clean_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'clean_train')\n",
    "print('clean_dir', clean_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "saved-fiction",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read clean audio\n",
    "clean_audio = pd.DataFrame({\n",
    "    \"recording_id\": [path.stem for path in Path(clean_dir).glob(\"*.mov\")],\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "martial-wonder",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert files to wav. format\n",
    "for file in clean_audio['recording_id']:\n",
    "    # files\n",
    "    mov_file = str(file + '.mov')\n",
    "    output = str(file + '.wav')\n",
    "    # convert mov to wav                                                            \n",
    "    sound = AudioSegment.from_file(mov_file, format=\"mov\")\n",
    "    sound = sound.set_channels(1)\n",
    "    sound.export(output, format=\"wav\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alive-sleeve",
   "metadata": {},
   "source": [
    "## Create noisy audio files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "filled-advice",
   "metadata": {},
   "outputs": [],
   "source": [
    "# change currnet directory  \n",
    "os. chdir('/Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "positive-wholesale",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read audio\n",
    "def audioread(path, norm = True, start=0, stop=None):\n",
    "    path = os.path.abspath(path)\n",
    "    if not os.path.exists(path):\n",
    "        raise ValueError(\"[{}] does not exist!\".format(path))\n",
    "    try:\n",
    "        x, sr = sf.read(path, start=start, stop=stop)\n",
    "    except RuntimeError:  # fix for sph pcm-embedded shortened v2\n",
    "        print('WARNING: Audio type not supported')\n",
    "\n",
    "    if len(x.shape) == 1:  # mono\n",
    "        if norm:\n",
    "            rms = (x ** 2).mean() ** 0.5\n",
    "            scalar = 10 ** (-25 / 20) / (rms)\n",
    "            x = x * scalar\n",
    "        return x, sr\n",
    "    else:  # multi-channel\n",
    "        x = x.T\n",
    "        x = x.sum(axis=0)/x.shape[0]\n",
    "        if norm:\n",
    "            rms = (x ** 2).mean() ** 0.5\n",
    "            scalar = 10 ** (-25 / 20) / (rms)\n",
    "            x = x * scalar\n",
    "        return x, sr\n",
    "    \n",
    "# Funtion to write audio    \n",
    "def audiowrite(data, fs, destpath, norm=False):\n",
    "    if norm:\n",
    "        rms = (data ** 2).mean() ** 0.5\n",
    "        scalar = 10 ** (-25 / 10) / (rms+eps)\n",
    "        data = data * scalar\n",
    "        if max(abs(data))>=1:\n",
    "            data = data/max(abs(data), eps)\n",
    "    \n",
    "    destpath = os.path.abspath(destpath)\n",
    "    destdir = os.path.dirname(destpath)\n",
    "    \n",
    "    if not os.path.exists(destdir):\n",
    "        os.makedirs(destdir)\n",
    "    \n",
    "    sf.write(destpath, data, fs)\n",
    "    return\n",
    "\n",
    "# Function to mix clean speech and noise at various signal to noise ratio (SNR) levels\n",
    "def snr_mixer(clean, noise, snr):\n",
    "    # Normalizing to -25 dB FS\n",
    "    rmsclean = (clean**2).mean()**0.5\n",
    "    scalarclean = 10 ** (-25 / 20) / rmsclean\n",
    "    clean = clean * scalarclean\n",
    "    \n",
    "    rmsnoise = (noise**2).mean()**0.5\n",
    "    scalarnoise = 10 ** (-25 / 20) /rmsnoise\n",
    "    noise = noise * scalarnoise\n",
    "   \n",
    "    # Set the noise level for a given SNR\n",
    "    noisescalar = np.sqrt(rmsclean / (10**(snr/20)) / rmsnoise)\n",
    "    noisenewlevel = noise * noisescalar\n",
    "    noisyspeech = clean + noisenewlevel\n",
    "    return clean, noisenewlevel, noisyspeech\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "intended-phenomenon",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration for generating Noisy Speech Dataset\n",
    "\n",
    "# - sampling_rate: Specify the sampling rate. Default is 16 kHz\n",
    "# - audioformat: default is .wav\n",
    "# - audio_length: Max Length of each audio clip (noisy and clean speech) in seconds that will be generated by augmenting utterances. \n",
    "# - silence_length: Duration of silence introduced between clean speech utterances.\n",
    "# - total_hours: Total number of hours of data required. Units are in hours. \n",
    "# - snr_lower: Lower bound for SNR required (default: 0 dB)\n",
    "# - snr_upper: Upper bound for SNR required (default: 40 dB)\n",
    "# - total_snrlevels: Number of SNR levels required (default: 5, which means there are 5 levels between snr_lower and snr_upper)\n",
    "# - noise_dir: Default is None. But specify the noise directory path if noise files are not in the source directory\n",
    "# - Speech_dir: Default is None. But specify the speech directory path if speech files are not in the source directory\n",
    "# - noise_types_excluded: Noise files starting with the following tags to be excluded in the noise list. Example: noise_types_excluded: Babble, AirConditioner\n",
    "#                         Specify 'None' if no noise files to be excluded.\n",
    "\n",
    "cfg={\n",
    "'sampling_rate': 44100,\n",
    "'audioformat': '*.wav',\n",
    "'audio_length': 60,\n",
    "'silence_length': 0.2,\n",
    "'total_hours': 1 ,\n",
    "'snr_lower': 0,\n",
    "'snr_upper': 40,\n",
    "'total_snrlevels': 5,  \n",
    "\n",
    "'noise_dir': None,\n",
    "'speech_dir': None,\n",
    "'noise_types_excluded': None\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "unknown-malpractice",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clean_dir /Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2/clean_train\n",
      "noise_dir /Users/michliu/Documents/HSBC - Data scientist/audio/cantonese2/noise_train\n"
     ]
    }
   ],
   "source": [
    "# Path to directories\n",
    "clean_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'clean_train')\n",
    "print('clean_dir', clean_dir)\n",
    "noise_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'noise_train')\n",
    "print('noise_dir', noise_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "associate-hundred",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up configurations \n",
    "snr_lower = int(cfg['snr_lower'])\n",
    "snr_upper = int(cfg['snr_upper'])\n",
    "total_snrlevels = int(cfg['total_snrlevels'])\n",
    "fs = float(cfg[\"sampling_rate\"])\n",
    "audioformat = cfg[\"audioformat\"]\n",
    "total_hours = float(cfg[\"total_hours\"])\n",
    "audio_length = float(cfg[\"audio_length\"])\n",
    "silence_length = float(cfg[\"silence_length\"])\n",
    "\n",
    "# Create folders for output files\n",
    "noisyspeech_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'NoisySpeech_training')\n",
    "if not os.path.exists(noisyspeech_dir):\n",
    "    os.makedirs(noisyspeech_dir)\n",
    "clean_proc_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'CleanSpeech_training')\n",
    "if not os.path.exists(clean_proc_dir):\n",
    "    os.makedirs(clean_proc_dir)\n",
    "noise_proc_dir = os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), 'Noise_training')\n",
    "if not os.path.exists(noise_proc_dir):\n",
    "    os.makedirs(noise_proc_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "worldwide-general",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_secs = total_hours*60*60\n",
    "total_samples = int(total_secs * fs)\n",
    "audio_length = int(audio_length*fs)\n",
    "SNR = np.linspace(snr_lower, snr_upper, total_snrlevels)\n",
    "cleanfilenames = glob.glob(os.path.join(clean_dir, audioformat))\n",
    "if cfg[\"noise_types_excluded\"]==None:\n",
    "    noisefilenames = glob.glob(os.path.join(noise_dir, audioformat))\n",
    "else:\n",
    "    filestoexclude = cfg[\"noise_types_excluded\"].split(',')\n",
    "    noisefilenames = glob.glob(os.path.join(noise_dir, audioformat))\n",
    "    for i in range(len(filestoexclude)):\n",
    "        noisefilenames = [fn for fn in noisefilenames if not os.path.basename(fn).startswith(filestoexclude[i])]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "honest-blank",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CopyMachine_2\n",
      "noisy_Cantonese5_SNRdb_0_CopyMachine_2.wav\n",
      "noisy_Cantonese5_SNRdb_10_CopyMachine_2.wav\n",
      "noisy_Cantonese5_SNRdb_20_CopyMachine_2.wav\n",
      "noisy_Cantonese5_SNRdb_30_CopyMachine_2.wav\n",
      "noisy_Cantonese5_SNRdb_40_CopyMachine_2.wav\n",
      "NeighborSpeaking_1\n",
      "noisy_Cantonese1_SNRdb_0_NeighborSpeaking_1.wav\n",
      "noisy_Cantonese1_SNRdb_10_NeighborSpeaking_1.wav\n",
      "noisy_Cantonese1_SNRdb_20_NeighborSpeaking_1.wav\n",
      "noisy_Cantonese1_SNRdb_30_NeighborSpeaking_1.wav\n",
      "noisy_Cantonese1_SNRdb_40_NeighborSpeaking_1.wav\n",
      "Field_1\n",
      "noisy_Cantonese1_SNRdb_0_Field_1.wav\n",
      "noisy_Cantonese1_SNRdb_10_Field_1.wav\n",
      "noisy_Cantonese1_SNRdb_20_Field_1.wav\n",
      "noisy_Cantonese1_SNRdb_30_Field_1.wav\n",
      "noisy_Cantonese1_SNRdb_40_Field_1.wav\n",
      "Restaurant_1\n",
      "noisy_Cantonese4_SNRdb_0_Restaurant_1.wav\n",
      "noisy_Cantonese4_SNRdb_10_Restaurant_1.wav\n",
      "noisy_Cantonese4_SNRdb_20_Restaurant_1.wav\n",
      "noisy_Cantonese4_SNRdb_30_Restaurant_1.wav\n",
      "noisy_Cantonese4_SNRdb_40_Restaurant_1.wav\n",
      "Metro_1\n",
      "noisy_Cantonese7_SNRdb_0_Metro_1.wav\n",
      "noisy_Cantonese7_SNRdb_10_Metro_1.wav\n",
      "noisy_Cantonese7_SNRdb_20_Metro_1.wav\n",
      "noisy_Cantonese7_SNRdb_30_Metro_1.wav\n",
      "noisy_Cantonese7_SNRdb_40_Metro_1.wav\n",
      "Square_1\n",
      "noisy_Cantonese5_SNRdb_0_Square_1.wav\n",
      "noisy_Cantonese5_SNRdb_10_Square_1.wav\n",
      "noisy_Cantonese5_SNRdb_20_Square_1.wav\n",
      "noisy_Cantonese5_SNRdb_30_Square_1.wav\n",
      "noisy_Cantonese5_SNRdb_40_Square_1.wav\n",
      "Metro_1\n",
      "noisy_Cantonese6_SNRdb_0_Metro_1.wav\n",
      "noisy_Cantonese6_SNRdb_10_Metro_1.wav\n",
      "noisy_Cantonese6_SNRdb_20_Metro_1.wav\n",
      "noisy_Cantonese6_SNRdb_30_Metro_1.wav\n",
      "noisy_Cantonese6_SNRdb_40_Metro_1.wav\n",
      "Office_1\n",
      "noisy_Cantonese1_SNRdb_0_Office_1.wav\n",
      "noisy_Cantonese1_SNRdb_10_Office_1.wav\n",
      "noisy_Cantonese1_SNRdb_20_Office_1.wav\n",
      "noisy_Cantonese1_SNRdb_30_Office_1.wav\n",
      "noisy_Cantonese1_SNRdb_40_Office_1.wav\n",
      "Babble_1\n",
      "noisy_Cantonese7_SNRdb_0_Babble_1.wav\n",
      "noisy_Cantonese7_SNRdb_10_Babble_1.wav\n",
      "noisy_Cantonese7_SNRdb_20_Babble_1.wav\n",
      "noisy_Cantonese7_SNRdb_30_Babble_1.wav\n",
      "noisy_Cantonese7_SNRdb_40_Babble_1.wav\n",
      "CafeTeria_1\n",
      "noisy_Cantonese2_SNRdb_0_CafeTeria_1.wav\n",
      "noisy_Cantonese2_SNRdb_10_CafeTeria_1.wav\n",
      "noisy_Cantonese2_SNRdb_20_CafeTeria_1.wav\n",
      "noisy_Cantonese2_SNRdb_30_CafeTeria_1.wav\n",
      "noisy_Cantonese2_SNRdb_40_CafeTeria_1.wav\n",
      "Square_1\n",
      "noisy_Cantonese5_SNRdb_0_Square_1.wav\n",
      "noisy_Cantonese5_SNRdb_10_Square_1.wav\n",
      "noisy_Cantonese5_SNRdb_20_Square_1.wav\n",
      "noisy_Cantonese5_SNRdb_30_Square_1.wav\n",
      "noisy_Cantonese5_SNRdb_40_Square_1.wav\n",
      "AirConditioner_1\n",
      "noisy_Cantonese1_SNRdb_0_AirConditioner_1.wav\n",
      "noisy_Cantonese1_SNRdb_10_AirConditioner_1.wav\n",
      "noisy_Cantonese1_SNRdb_20_AirConditioner_1.wav\n",
      "noisy_Cantonese1_SNRdb_30_AirConditioner_1.wav\n",
      "noisy_Cantonese1_SNRdb_40_AirConditioner_1.wav\n",
      "Traffic_1\n",
      "noisy_Cantonese7_SNRdb_0_Traffic_1.wav\n",
      "noisy_Cantonese7_SNRdb_10_Traffic_1.wav\n",
      "noisy_Cantonese7_SNRdb_20_Traffic_1.wav\n",
      "noisy_Cantonese7_SNRdb_30_Traffic_1.wav\n",
      "noisy_Cantonese7_SNRdb_40_Traffic_1.wav\n",
      "AirportAnnouncements_1\n",
      "noisy_Cantonese2_SNRdb_0_AirportAnnouncements_1.wav\n",
      "noisy_Cantonese2_SNRdb_10_AirportAnnouncements_1.wav\n",
      "noisy_Cantonese2_SNRdb_20_AirportAnnouncements_1.wav\n",
      "noisy_Cantonese2_SNRdb_30_AirportAnnouncements_1.wav\n",
      "noisy_Cantonese2_SNRdb_40_AirportAnnouncements_1.wav\n",
      "Bus_1\n",
      "noisy_Cantonese3_SNRdb_0_Bus_1.wav\n",
      "noisy_Cantonese3_SNRdb_10_Bus_1.wav\n",
      "noisy_Cantonese3_SNRdb_20_Bus_1.wav\n",
      "noisy_Cantonese3_SNRdb_30_Bus_1.wav\n",
      "noisy_Cantonese3_SNRdb_40_Bus_1.wav\n",
      "Hallway_1\n",
      "noisy_Cantonese1_SNRdb_0_Hallway_1.wav\n",
      "noisy_Cantonese1_SNRdb_10_Hallway_1.wav\n",
      "noisy_Cantonese1_SNRdb_20_Hallway_1.wav\n",
      "noisy_Cantonese1_SNRdb_30_Hallway_1.wav\n",
      "noisy_Cantonese1_SNRdb_40_Hallway_1.wav\n",
      "SqueakyChair_1\n",
      "noisy_Cantonese5_SNRdb_0_SqueakyChair_1.wav\n",
      "noisy_Cantonese5_SNRdb_10_SqueakyChair_1.wav\n",
      "noisy_Cantonese5_SNRdb_20_SqueakyChair_1.wav\n",
      "noisy_Cantonese5_SNRdb_30_SqueakyChair_1.wav\n",
      "noisy_Cantonese5_SNRdb_40_SqueakyChair_1.wav\n"
     ]
    }
   ],
   "source": [
    "# main\n",
    "\n",
    "filecounter = 0\n",
    "num_samples = 0\n",
    "    \n",
    "while num_samples < total_samples:\n",
    "    idx_s = np.random.randint(0, np.size(cleanfilenames))\n",
    "    clean, fs = audioread(cleanfilenames[idx_s])\n",
    "    \n",
    "    if len(clean)<audio_length:\n",
    "        clean = clean\n",
    "       \n",
    "        \n",
    "    else:\n",
    "            \n",
    "        while len(clean)<=audio_length:\n",
    "            idx_s = idx_s + 1\n",
    "            if idx_s >= np.size(cleanfilenames)-1:\n",
    "                idx_s = np.random.randint(0, np.size(cleanfilenames)) \n",
    "            newclean, fs = audioread(cleanfilenames[idx_s])\n",
    "            cleanconcat = np.append(clean, np.zeros(int(fs*silence_length)))\n",
    "            clean = np.append(cleanconcat, newclean)\n",
    "\n",
    "\n",
    "    idx_n = np.random.randint(0, np.size(noisefilenames))\n",
    "    noise, fs2 = audioread(noisefilenames[idx_n])\n",
    "    noise_file_name = noisefilenames[idx_n].split(\"/\")[-1].split('.')[0]\n",
    "    print(noise_file_name)\n",
    "    idx2 = idx_n\n",
    "    \n",
    "    # Resample data\n",
    "    new_rate = 44100\n",
    "    number_of_samples = round(len(noise) * float(new_rate) / fs2)\n",
    "    noise = sps.resample(noise, number_of_samples)\n",
    "                \n",
    "    if len(noise)>=len(clean):\n",
    "        noise = noise[0:len(clean)]\n",
    "        \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        while len(noise)<=len(clean):\n",
    "            idx_n = idx_n + 1\n",
    "            if idx_n >= np.size(noisefilenames)-1:\n",
    "                idx_n = np.random.randint(0, np.size(noisefilenames))\n",
    "            newnoise, fs2 = audioread(noisefilenames[idx_n])\n",
    "            idx2 = idx_n\n",
    "             # Resample data\n",
    "            new_rate = 44100\n",
    "            number_of_samples = round(len(noise) * float(new_rate) / fs2)\n",
    "            noise = sps.resample(noise, number_of_samples)\n",
    "            \n",
    "            noiseconcat = np.append(noise, np.zeros(int(fs*silence_length)))\n",
    "            noise = np.append(noiseconcat, newnoise)\n",
    "\n",
    "    noise = noise[0:len(clean)]\n",
    "    filecounter = filecounter + 1\n",
    "\n",
    "    for i in range(np.size(SNR)):\n",
    "        clean_snr, noise_snr, noisy_snr = snr_mixer(clean=clean, noise=noise, snr=SNR[i])\n",
    "        noisyfilename = 'noisy_'+(cleanfilenames[idx_s].split(\"/\")[-1].split('.')[0])+'_SNRdb_'+str(int(SNR[i]))+ \"_\"+noise_file_name +'.wav'\n",
    "        cleanfilename = 'clnsp_'+(cleanfilenames[idx_s].split(\"/\")[-1].split('.')[0])+'.wav'\n",
    "        noisefilename = 'noisy_'+(cleanfilenames[idx_s].split(\"/\")[-1].split('.')[0])+'_SNRdb_'+str(int(SNR[i]))+ \"_\"+ noise_file_name +'.wav'\n",
    "        noisypath = os.path.join(noisyspeech_dir, noisyfilename)\n",
    "        cleanpath = os.path.join(clean_proc_dir, cleanfilename)\n",
    "        noisepath = os.path.join(noise_proc_dir, noisefilename)\n",
    "        print(noisyfilename )\n",
    "        audiowrite(noisy_snr, fs, noisypath, norm=False)\n",
    "        audiowrite(clean, fs, cleanpath, norm=False)\n",
    "        audiowrite(noise_snr, fs, noisepath, norm=False)\n",
    "        num_samples = num_samples + len(noisy_snr)\n",
    "        \n",
    "        #sd.play(clean, fs)\n",
    "        #status = sd.wait() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedicated-attempt",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
